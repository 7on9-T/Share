Day03 基础入门-Web架构&OSS存储&CDN加速&反向代理&WAF防护
=
#WAF：Web Application Firewall   Web应用防火墙
-
### 原理
一种专门用于保护 Web 应用程序免受各类网络攻击、保障其安全运行的重要安全防护工具
影响：常规Web安全测试手段会受到拦截  
演示：IIS下免费D盾防护软件https://www.d99net.net/  
### 模拟
Windows Server 2022 + IIS + D盾  
尝试上传后门1.asp  
打开后门时会被D盾防护阻止（安全测试手法会被拦截）  

### WAF分类  
#### 非嵌入型  
>* 	硬件型WAF  
>以硬件形式部署在链路中，支持多种部署方式，当串联到链路中时可以拦截恶意流量，在旁路监听时只记录攻击不拦截
代表产品：lmperva、天清WAG等  
>*	软件型WAF  
>以软件形式安装在服务器上，可直接检测服务器是否存在webshell、是否有文件被创建等
代表产品：安全狗，云锁，D盾等  
>*	云WAF  
>一般以反向代理的形式工作，通过配置NS或CNAME记录，使得对网站的请求报文优先经过WAF主机，经过WAF主机过滤后，将被认为无害的请求报文再发送给实际网站服务器进行请求，可以认为是带防护功能的CDN
代表产品：阿里云云盾，腾讯云WAF等  
#### 嵌入型  
>* 网站内置的WAF  
>也叫自定义WAF。 直接镶嵌在代码中，即开发人员为了网站的安全，会在可能遭受攻击的地方增加一些安全防护代码，比如过滤敏感字符，对潜在的威胁字符进行编码、转义等。网站内置的WAF与业务更加契合。  

#CDN: Content Delivery Network 内容分发服务
-
### 原理：
旨在提高访问速度  
### 影响：
隐藏真实源IP，导致对目标测试错误  
### 演示：
阿里云备案域名全局CDN加速服务

#OSS: Object Storage Service 对象存储
-
原理：对象存储（云存储服务）  
影响：  
演示：Windows Server 2022 + cloudreve + 阿里云OSS  
*  Cloudreve：  
是一款开源的网盘系统，它提供了类似于百度网盘、OneDrive 等网盘的功能，支持多种存储方式，如本地存储、阿里云 OSS、七牛云存储、腾讯云 COS 等，并且具有用户管理、文件管理、权限管理等功能。  
>主要功能  
>*  多存储策略：可以将文件存储在不同的存储后端，用户可以根据自身需求选择适合的存储方式，如将重要文件存储在阿里云 OSS 上，将普通文件存储在本地存储等。  
>*	用户管理：支持多用户，可对用户进行添加、删除、权限设置等操作，方便对不同用户的文件进行管理和访问控制。  
>*	文件管理：提供文件的上传、下载、删除、移动、重命名、分享等功能，用户可以方便地管理自己的文件。  
>*	权限管理：可以对用户或用户组设置不同的权限，例如某些用户只能下载文件，而另一些用户可以上传和删除文件。  
>*	文件分享：支持生成文件的分享链接，方便用户将文件分享给其他人，并且可以设置分享的有效期和访问密码等。  

>1.	下载cloudreve https://github.com/cloudreve/Cloudreve/
>2.	扔到服务器里
>3.	运行cloudreve.exe
>4.	使用初始密码登录
>5.	登陆管理
>6.	配置存储信息
>7.	更改用户组存储属性  



阿里云OSS： 
-
阿里云 OSS（Object Storage Service）是阿里云提供的一种海量、安全、低成本、高可靠的云存储服务。它可以存储各种类型的数据，如图片、视频、文档等，并提供了多种数据管理和处理功能。
1. 功能特性
*	海量存储：可以存储海量的数据，适合存储各种大小的文件，从几 KB 到数 TB 都可以轻松应对。
*	高可靠性：通过数据冗余和备份机制，保证数据的高可靠性，通常具有多个备份，即使部分存储设备出现故障，数据也不会丢失。
*	高可用性：提供高可用的存储服务，确保用户可以随时访问存储的数据，服务可用性较高。
*	数据安全：支持多种安全机制，如访问控制、加密存储、传输加密等，保障数据的安全性。
*	数据处理：支持对存储的数据进行简单的处理，如图片处理（裁剪、缩放、格式转换等）。
2. 主要概念
*	Bucket：可以理解为存储对象的容器，类似于文件系统中的文件夹，用于存储和管理对象。每个对象都必须存储在一个 Bucket 中，用户可以创建多个 Bucket 来分类存储不同的数据。
*	Object：是存储的基本单元，也就是实际存储的数据，可以是文件、图片、视频等。每个对象都有一个唯一的键（Key），类似于文件的路径，用于标识对象在 Bucket 中的位置。
1.	开通OSS
2.	新建Bucket
3.	配置Bucket属性
4.	配置Access 访问

为什么要使用第三方存储？
-
1)	静态文件会占用大量带宽
2)	加载速度
3)	存储空间
影响：上传的文件或解析的文档均来自于OSS资源，无法解析，单独存储
1.	修复上传安全
2.	文件解析不一样
3.	但Access Key隐患

正反向代理 —— 一、正向代理：  
-
>正向代理是位于客户端和目标服务器之间的一种代理服务，它代理客户端去访问目标服务器。客户端将请求发送给正向代理服务器，然后由正向代理服务器向目标服务器发起请求，目标服务器将响应返回给正向代理服务器，最后正向代理服务器再把响应传递回客户端。  
例如，在企业内部网络中，员工想要访问外部的一些网站，但企业网络设置了访问限制，通过配置正向代理服务器，员工的浏览器等客户端将访问请求发送给正向代理服务器，由它去和外部目标网站进行交互，就好像是代理服务器在代替员工去访问网站一样，外部网站看到的请求来源也是代理服务器的 IP 地址，而不是员工客户端的真实 IP 地址。  

作用及应用场景：  

 	突破访问限制：可以帮助客户端绕过一些网络访问限制，比如突破某些地区对特定网站的封锁，或者绕过企业、学校等网络环境下设置的访问策略，实现访问外部资源的目的。  
 	提高访问效率：正向代理服务器可以缓存一些经常被访问的资源，当下次客户端再请求相同资源时，代理服务器直接从缓存中提取并返回给客户端，无需再向目标服务器发起请求，从而节省了网络带宽、加快了客户端的响应速度。  
 	隐藏客户端信息：由于目标服务器看到的请求来源是正向代理服务器的 IP 地址，所以客户端的真实 IP 等信息得以隐藏，一定程度上保护了客户端的隐私，例如在一些不想暴露自身网络位置的浏览场景中可发挥作用。    

正反向代理 —— 二、反向代理：
-
>反向代理则是位于服务器端，它代理的是后端的多个真实服务器，对外接收客户端的所有访问请求，然后根据一定的规则（如负载均衡规则、服务器健康状态等）将请求转发到后端的某一个真实服务器上，由真实服务器处理请求并返回响应，反向代理服务器再将这个响应传递回客户端。  
比如，一个大型的电商网站，背后有多个 Web 服务器来处理用户的访问请求，为了便于统一管理、实现负载均衡以及提高安全性等目的，会在前端设置反向代理服务器。客户端访问电商网站时，请求先到反向代理服务器，它再根据各服务器的负载情况等因素将请求合理分配到其中一台 Web 服务器上进行处理，最后把处理结果反馈给客户端。  

作用及应用场景：  
> 	负载均衡：通过合理分配客户端的请求到不同的后端服务器，可以避免单个服务器负载过重，使各服务器的资源得到均衡利用，提高整体的服务性能和稳定性，确保大量客户端访问时也能快速响应。例如在高并发访问的网站中，通过反向代理按照轮询、权重等方式将请求分配到多台服务器上，保障业务的顺畅运行。  

> 	提高安全性：反向代理服务器可以隐藏后端真实服务器的 IP 地址等信息，外界客户端只能看到反向代理服务器的 IP，这样即使有攻击行为，也是针对代理服务器，减少了后端真实服务器直接被攻击的风险，起到一定的安全防护作用。

> 	方便服务器维护与扩展：当需要对后端服务器进行升级、维护或者增加新的服务器时，只需要在反向代理服务器端进行相应的配置调整即可，不需要客户端知晓或进行任何更改，便于网站的持续运营和服务器资源的灵活扩充。  

总的来说  
-
所谓的反向代理即跳转  
正向代理为客户端服务，客户端主动建立代理访问目标（不代理不可达）  
反向代理为服务器端服务，服务器主动转发数据给可访问地址（不主动不可达）  
原理：通过网络反向代理转发真实服务达到访问目的  
影响：访问目标只是一个代理，非真实应用服务器  
注意：正向代理和反向代理都是解决访问不可达的问题，但由于反向代理中多出一个可以重定向解析的功能操作，导致反代理出的站点指向和真实应用毫无关系！  

#负载均衡:类似于容灾备份
-
原理：分摊到多个操作单元上进行执行，共同完成工作任务  
影响：有多个服务器加载服务，测试过程中存在多个目标情况

演示：Nginx反向代理和负载均衡配置.
-

打开nginx配置文件
一、	基于域名的反向代理
假设要将对 example1.com 和 example2.com 的请求分别反向代理到不同的后端服务器。
```nginx
server {
    server_name example1.com;
    proxy_pass http://backend1.example.com;
}

server {
    server_name example2.com;
    proxy_pass http://backend2.example.com;
}
```
当用户访问 example1.com 时，Nginx 会将请求反向代理到 http://backend1.example.com；而访问 example2.com 时，请求则会被转发到 http://backend2.example.com 。
二、	基于路径的反向代理
如果要将以 /api 开头的请求转发到后端服务 http://backend-api.example.com，其他请求保持不变。
```nginx
server {
    location /api {
        proxy_pass http://backend-api.example.com;
    }
}
```
当用户访问比如 /api/users 时，Nginx 就会把该请求反向代理到 http://backend-api.example.com ，而访问其他路径如 /home 等就按常规处理。
三、	基于负载均衡的反向代理
假设有三个后端服务器，分别是 backend1.example.com、backend2.example.com 和 backend3.example.com。
```nginx
upstream my_backends {
    server backend1.example.com;
    server backend2.example.com;
    server backend3.example.com;
}

server {
    proxy_pass http://my_backends;
}
```
在这个例子中，Nginx 会将请求按照一定的策略（通常是轮询）均衡地分发到这三个后端服务器上。还可以为每个后端服务器设置权重、最大失败次数和失败超时时间等参数，例如：
```nginx
upstream my_backends {
    server backend1.example.com weight=3;
    server backend2.example.com weight=2;
    server backend3.example.com weight=1;
    server backend1.example.com max_fails=3;
    server backend1.example.com fail_timeout=30s;
}
```
四、	动静分离型反向代理
假设一个前端服务器（Nginx）和两个后端服务器（Server1 和 Server2），其中 Server1 处理动态请求，Server2 处理静态请求。
```nginx
upstream servers {
    server Server1_IP:Server1_Port;
    server Server2_IP:Server2_Port;
}

server {
    location ~ \.(jpg|png|gif|css|js)$ {
        proxy_pass http://Server2_IP:Server2_Port;
    }

    location / {
        proxy_pass http://Server1_IP:Server1_Port;
    }
}
```
通过以上配置，Nginx 会根据请求的路径将动态请求转发到 Server1，将静态请求转发到 Server2。
五、	反向代理添加请求头
在反向代理时，有时需要将客户端的真实 IP 等信息传递给后端服务器，可以使用 proxy_set_header 指令。
```nginx
server {
    location / {
        proxy_pass http://backend_server;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}
```
六、	反向代理设置超时时间
可以使用 proxy_connect_timeout、proxy_read_timeout 和 proxy_send_timeout 等指令设置连接、读取和发送的超时时间。
```nginx
server {
    location / {
        proxy_pass http://backend_server;
        proxy_connect_timeout 10s;
        proxy_read_timeout 30s;
        proxy_send_timeout 30s;
    }
}
```

建议：手动在宝塔配置Nginx反向代理和负载均衡，练习一下
